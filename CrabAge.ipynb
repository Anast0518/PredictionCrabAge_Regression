{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Рубашевская Анастасия 3.9\n",
        "Тема: Предсказание возраста краба на основе метрических данных методами регрессии"
      ],
      "metadata": {
        "id": "CVJu51D15EF6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "1WO5rQzk_FGE"
      },
      "outputs": [],
      "source": [
        "from sklearn.neighbors import RadiusNeighborsRegressor\n",
        "from sklearn.model_selection import train_test_split # импортируем из библиотеки  sklearn функцию train_test_split\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.linear_model import TheilSenRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.linear_model import RANSACRegressor\n",
        "from sklearn.linear_model import HuberRegressor\n",
        "# импортируем mean_squared_error из библиотеки Scikit-learn, которая используется для вычисления среднеквадратичной ошибки\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.linear_model import ElasticNet\n",
        "from sklearn.linear_model import Ridge\n",
        "from sklearn.linear_model import Lasso\n",
        "from sklearn.svm import LinearSVR\n",
        "from sklearn.svm import SVR\n",
        "import pandas # библиотека для анализа данных\n",
        "import numpy # библиотека, которая поддерживает многомерные массивы и математические функции\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy.seterr(invalid='ignore') # игнорирует numpy-евские предупреждения о преобразовании данных\n",
        "data = pandas.read_csv(\"CrabAgePrediction.csv\") # читаем csv-файл через библиотеку pandas CrabAgePrediction.csv\n",
        "replace_dict = {'I': 1, 'F': 2, 'M': 3} # преобразовываем строчные данные (пол краба) в цифру\n",
        "data = data.replace(replace_dict)\n",
        "# приводим данные csv файла к структуре датасета как в sklearn\n",
        "dataset = {'data': data[[data.columns[i] for i in range(8)]].to_numpy(), # данные для обучения\n",
        "             'target': data[data.columns[8]].to_numpy(dtype=numpy.int64), # столбец возраста краба (счет от 0 до 8)\n",
        "             'DESCR': '\\n\\nCrabAgePrediction'} # название датасета\n",
        "\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "print(\"Датасет: \", dataset['DESCR'].splitlines()[2]) #вывод названия датасета\n",
        "print(Counter(data.iloc[:, 8]))\n",
        "print(\"-----------------------------------------------------------------\")\n",
        "# деление на тестовую и тренировочные части, где 70% на тренировку\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(dataset['data'], dataset['target'], train_size = 0.7)\n",
        "# пропускаем данные через полиномиальную регрессию. degree - степень полинома\n",
        "Poly_train, Poly_test = PolynomialFeatures(degree = 3).fit_transform(X_train), PolynomialFeatures(degree = 3).fit_transform(X_test)\n",
        "# массив всех регрессионных моделей\n",
        "AllModels = ['KNeighborsRegressor', 'RadiusNeighborsRegressor', 'LinearSVR', 'SVR', 'LinearRegression', 'Ridge', 'Lasso', 'ElasticNet',\n",
        "             'LinearRegression + Полиномиальная регрессия', 'Ridge + Полиномиальная регрессия', 'Lasso + Полиномиальная регрессия', 'ElasticNet + Полиномиальная регрессия',\n",
        "             'Полиномиальная регрессия + TheilSenRegressor', 'Полиномиальная регрессия + HuberRegressor', 'RANSACRegressor + LinearRegression', 'RANSACRegressor + Ridge',\n",
        "             'RANSACRegressor + Lasso', 'RANSACRegressor + ElasticNet', 'RANSACRegressor + LinearRegression + Полиномиальная регрессия',\n",
        "             'RANSACRegressor + Ridge + Полиномиальная регрессия', 'RANSACRegressor + Lasso + Полиномиальная регрессия', 'RANSACRegressor + ElasticNet + Полиномиальная регрессия']\n",
        "MSEOfModels = numpy.array([]) # пустой массив лучших"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIwuk1sJ5rKu",
        "outputId": "99d74815-b00a-4eae-ccce-74fca505e004"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------------------------\n",
            "Датасет:  CrabAgePrediction\n",
            "Counter({9: 640, 10: 598, 8: 520, 11: 459, 7: 357, 12: 248, 6: 241, 13: 195, 14: 122, 5: 107, 15: 96, 16: 62, 17: 54, 4: 53, 18: 38, 19: 31, 20: 23, 21: 14, 3: 13, 23: 7, 22: 6, 24: 2, 27: 2, 26: 1, 2: 1, 1: 1, 29: 1, 25: 1})\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# KNeighborsRegressor\n",
        "print(\"KNeighborsRegressor\")\n",
        "BestKNeighbor = numpy.array([]) # создаю пустой массив для среднеквадратичных ошибок\n",
        "# Проход по числу соседей от 1 до 19 включительно\n",
        "for n in range(1, 20):\n",
        "   # Для каждого значения n создается модель KNeighborsRegressor с соответствующим числом соседей\n",
        "   model = KNeighborsRegressor(n_neighbors = n)\n",
        "   # обучение модели по тренировочным данным\n",
        "   model.fit(X_train, Y_train)\n",
        "   \"\"\"Вычисляется среднеквадратичная ошибка на тестовых данных (Y_test)\n",
        "   для текущей модели с числом соседей n и добавляется в массив BestKNeighbor.\"\"\"\n",
        "   BestKNeighbor = numpy.append(BestKNeighbor, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "\n",
        "print(BestKNeighbor) #вывод массива среднеквадратичных ошибок\n",
        "# Вывод лучшего числа соседей, которое соответствует минимальной среднеквадратической ошибке\n",
        "print(\"Лучшее число соседей\", numpy.argmin(BestKNeighbor) + 1, \"с среднеквадратичной ошибкой\", BestKNeighbor[numpy.argmin(BestKNeighbor)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestKNeighbor[numpy.argmin(BestKNeighbor)])\n",
        "print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEt2pJ4M6KpX",
        "outputId": "7f7f1ef8-ec83-4091-8713-365a7f2f71e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsRegressor\n",
            "[8.04537671 6.33154966 5.68807078 5.37307363 5.16044521 5.12611777\n",
            " 5.14477914 5.04525631 4.97878615 4.9322089  4.93841277 4.89484042\n",
            " 4.85482188 4.8542118  4.85248478 4.78339376 4.79614696 4.76175112\n",
            " 4.75335351]\n",
            "Лучшее число соседей 19 с среднеквадратичной ошибкой 4.753353508139491\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RadiusNeighborsRegressor\n",
        "print(\"RadiusNeighborsRegressor\")\n",
        "BestRadiusNeighbor = numpy.array([])\n",
        "# Цикл прохода по радиусам от 1 до 19  включительно\n",
        "for r in range(1, 20):\n",
        "   model = RadiusNeighborsRegressor(radius = r) #создание модели с указанным радиусом r\n",
        "   # Радиус здесь служит в качестве параметра, определяющего радиус окрестности, в пределах которой находятся соседи\n",
        "   model.fit(X_train, Y_train) # обучение модели по тренировочным данным\n",
        "   \"\"\" Вычисляется среднеквадратичная ошибка на тестовых данных (Y_test)\n",
        "   для текущей модели с радиусом r и добавляется в массив BestRadiusNeighbor.\n",
        "   Здесь используется функция mean_squared_error для расчета среднеквадратичной ошибки.\"\"\"\n",
        "   BestRadiusNeighbor = numpy.append(BestRadiusNeighbor, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "\n",
        "print(BestRadiusNeighbor) # Выводим массив среднеквадратичных ошибок\n",
        "# Вывой информации о лучшем радиусе, который соответствует наименьшей среднеквадратической ошибке\n",
        "print(\"Лучший радиус\", numpy.argmin(BestRadiusNeighbor) + 1, \"с среднеквадратичной ошибкой\", BestRadiusNeighbor[numpy.argmin(BestRadiusNeighbor)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestRadiusNeighbor[numpy.argmin(BestRadiusNeighbor)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tqLazx6m7APn",
        "outputId": "0258e97d-ea67-4c10-f04f-7f74be777c67"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RadiusNeighborsRegressor\n",
            "[1.48582198e+37 2.76770761e+36 1.16535057e+36 4.37006464e+35\n",
            " 7.28344107e+34 7.28344107e+34 7.28344107e+34 7.28344107e+34\n",
            " 7.28344107e+34 6.57177385e+00 6.66816310e+00 6.76066285e+00\n",
            " 6.83218501e+00 6.93489538e+00 7.01643947e+00 7.09995194e+00\n",
            " 7.18575510e+00 7.27047148e+00 7.36569422e+00]\n",
            "Лучший радиус 10 с среднеквадратичной ошибкой 6.571773848351284\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LinearSVR\n",
        "print(\"LinearSVR\")\n",
        "model = LinearSVR(dual = True, max_iter = 100000)\n",
        "\"\"\"dual=True: Это логический параметр, который указывает, следует ли использовать двойственную или прямую форму оптимизации.\n",
        "Параметр dual влияет на способ оптимизации алгоритма. Если dual=True, алгоритм оптимизирует двойственную форму задачи оптимизации.\n",
        "max_iter = 100000 - максимальное число итераций определяется для того, чтобы модель точно доучилась до конца\"\"\"\n",
        "\n",
        "model.fit(X_train, Y_train) # обучение модели на тренировочных данных\n",
        "\n",
        "\"\"\"Расчитываем среднеквадратическую ошибку между фактическими целевыми значениями тестовых данных Y_test\n",
        "и предсказанными значениями, полученными с помощью метода predict(), модели на тестовых данных X_test.\n",
        "Она оценивает, насколько хорошо модель предсказывает целевую переменную.\"\"\"\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(\"Cреднеквадратичная ошибка linearSVR\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5ysqmqv7RtL",
        "outputId": "92df2518-dfb5-4640-97f0-44f2d557f55c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearSVR\n",
            "Cреднеквадратичная ошибка linearSVR 4.978322485558872\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SVR\n",
        "print(\"SVR\")\n",
        "kernels = ['linear', 'poly', 'rbf', 'sigmoid'] # массив ядер\n",
        "BestSVR = numpy.array([]) # пустой массив среднеквадратических ошибок\n",
        "# Цикл прохода по ядрам\n",
        "for kernel in kernels:\n",
        "   model = SVR(kernel = kernel) # создание модели с указанным ядром\n",
        "   model.fit(X_train, Y_train) # обучение модели на тренировочных данных\n",
        "   # заполняем массив среднеквадратических ошибок нашими значениями\n",
        "   BestSVR = numpy.append(BestSVR, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "# вывод сперва массива ядер, затем массива ошибок, чтобы понимать какому ядру соответствует какая ошибка\n",
        "print(kernels)\n",
        "print(BestSVR)\n",
        "# Вывод лучшего ядра, которое соответствует минимальной квадратической ошибке\n",
        "print(\"Лучшее ядро\", kernels[numpy.argmin(BestSVR)], \"с среднеквадратичной ошибкой\", BestSVR[numpy.argmin(BestSVR)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestSVR[numpy.argmin(BestSVR)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1H3yr_5l7v7D",
        "outputId": "f9846485-a2cd-491e-b4f6-f6c5b8376e8c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVR\n",
            "['linear', 'poly', 'rbf', 'sigmoid']\n",
            "[4.98950221e+00 6.97195792e+00 4.94312951e+00 9.47956355e+03]\n",
            "Лучшее ядро rbf с среднеквадратичной ошибкой 4.943129509581358\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# LinearRegression\n",
        "print(\"LinearRegression\")\n",
        "model = LinearRegression() # создается модель линейной регрессии\n",
        "model.fit(X_train, Y_train) # обучение модели на тренировочных данных\n",
        "# Расчет среднеквадратической ошибки и вывод\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(\"Cреднеквадратичная ошибка LinearRegression\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iIXZIn_7_wt",
        "outputId": "9f148a19-d744-4772-e9fd-34c1ed1ec80b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LinearRegression\n",
            "Cреднеквадратичная ошибка LinearRegression 4.872571838711208\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge\n",
        "print(\"Ridge\")\n",
        "BestRidge = numpy.array([]) # создаем пустой массив среднеквадратических ошибок\n",
        "# Цикл прохода по значениям а от 0 до 20 включительно\n",
        "for a in range(21):\n",
        "   # параметр регуляризации alpha (позволяет предотвратить переобучение модели) вычисляется как а/2 - таким образом в цикле делаю шаг 0.5\n",
        "   alpha = a / 2\n",
        "   model = Ridge(alpha = alpha) # создаем модель с указанным значением параметра alpha\n",
        "   model.fit(X_train, Y_train) # обучение модели по тренировочным данным\n",
        "   # Заполняем пустой массив ошибок расчетными значениями\n",
        "   BestRidge = numpy.append(BestRidge, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "\n",
        "print(BestRidge) # Вывод массива ошибок\n",
        "# Вывод информации о лучшем значении alpha, который соответствует наименьшей среднеквадратической ошибке\n",
        "print(\"Лучший alpha в Ridge\", numpy.argmin(BestRidge) / 2, \"с среднеквадратичной ошибкой\", BestRidge[numpy.argmin(BestRidge)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestRidge[numpy.argmin(BestRidge)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQc2vnhr8UsJ",
        "outputId": "b21df40c-ce0c-4dcb-9c31-e8d4ef67c77e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge\n",
            "[4.87257184 4.87421111 4.876605   4.87923909 4.88190456 4.88451388\n",
            " 4.88703175 4.88944655 4.89175763 4.89396931 4.89608807 4.89812103\n",
            " 4.9000753  4.90195762 4.90377424 4.90553083 4.90723254 4.908884\n",
            " 4.91048935 4.91205232 4.91357624]\n",
            "Лучший alpha в Ridge 0.0 с среднеквадратичной ошибкой 4.87257183871121\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso\n",
        "print(\"Lasso\")\n",
        "BestLasso = numpy.array([])\n",
        "# Цикл прохода по значениям а от 1 до 20 включительно\n",
        "for a in range(1, 21):\n",
        "   # параметр регуляризации alpha (позволяет предотвратить переобучение модели) вычисляется как а/2 - таким образом в цикле делаю шаг 0.5\n",
        "   alpha = a / 2\n",
        "   model = Lasso(alpha = alpha) # создание модели с указанным параметром alpha\n",
        "   model.fit(X_train, Y_train) # обучение модели по тренировочным данным\n",
        "   # Заполняем массив ошибок расчетными значениями\n",
        "   BestLasso = numpy.append(BestLasso, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "# вывод массива среднеквадратических ошибок\n",
        "print(BestLasso)\n",
        "# Вывод информации о лучшем параметре alpha, который соответствует минимальной среднеквадратической ошибки\n",
        "print(\"Лучший alpha в Lasso\", (numpy.argmin(BestLasso) + 1) / 2, \"с среднеквадратичной ошибкой\", BestLasso[numpy.argmin(BestLasso)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestLasso[numpy.argmin(BestLasso)])\n",
        "print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YtGv64Sg8sOO",
        "outputId": "32547253-d0fe-44ca-c6a6-96eb93f3c18c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso\n",
            "[5.46520725 5.94326123 6.51448886 7.09674119 7.11245955 7.1255724\n",
            " 7.14141201 7.15997837 7.1812715  7.20529138 7.23203803 7.26151143\n",
            " 7.29371159 7.32863851 7.36629219 7.40667263 7.44977983 7.49561378\n",
            " 7.5441745  7.59546197]\n",
            "Лучший alpha в Lasso 0.5 с среднеквадратичной ошибкой 5.465207251515108\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ElasticNet\n",
        "print(\"ElasticNet\")\n",
        "BestElastic = numpy.array([])\n",
        "\n",
        "for ratio in range(10):\n",
        "   alpha = ratio * 2 + 1\n",
        "   l1 = (10 - ratio) / 10\n",
        "\n",
        "   model = ElasticNet(alpha = alpha, l1_ratio = l1, max_iter = 100000)\n",
        "   model.fit(X_train, Y_train)\n",
        "   BestElastic = numpy.append(BestElastic, mean_squared_error(Y_test, model.predict(X_test)))\n",
        "\n",
        "print(BestElastic)\n",
        "print(\"Лучшие alpha и l1_ratio в ElasticNet\", numpy.argmin(BestElastic) * 2 + 1, (10 - numpy.argmin(BestElastic)) / 10, \"с среднеквадратичной ошибкой\", BestElastic[numpy.argmin(BestElastic)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestElastic[numpy.argmin(BestElastic)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8Py6TVZ9RWC",
        "outputId": "3be6e93f-a2be-482b-9e4b-187caa7e7a76"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet\n",
            "[5.94326123 7.1182397  7.16418038 7.21079771 7.24603565 7.26253123\n",
            " 7.25757499 7.23281234 7.19372824 7.07196159]\n",
            "Лучшие alpha и l1_ratio в ElasticNet 1 1.0 с среднеквадратичной ошибкой 5.943261227682373\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Линейная регрессия + Полиномиальная регрессия\n",
        "print(\"Линейная регрессия + Полиномиальная регрессия\")\n",
        "model = LinearRegression() # создание модели линейной регрессии\n",
        "model.fit(Poly_train, Y_train) # обучение модели по тренировочным полимеальным данным и тренировочным Y\n",
        "# расчет среднеквадратической ошибки и ее вывод\n",
        "mse = mean_squared_error(Y_test, model.predict(Poly_test))\n",
        "print(\"Cреднеквадратичная ошибка Полиномиальная + LinearRegression\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sLJCdGT9nd7",
        "outputId": "289292e3-bbda-4f8b-e476-e441a2a125fd"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Линейная регрессия + Полиномиальная регрессия\n",
            "Cреднеквадратичная ошибка Полиномиальная + LinearRegression 5.108614410448293\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ridge + Полиномиальная регрессия\n",
        "print(\"Ridge + Полиномиальная регрессия\")\n",
        "BestRidge = numpy.array([]) # создание пустого массива среднеквадратических ошибок\n",
        "# Цикл прохода по значениям а от 0 до 20 включительно\n",
        "for a in range(21):\n",
        "   # параметр регуляризации alpha (позволяет избежать переобучение модели) вычисляется как а/2 - таким образом в цикле делаю шаг 0.5\n",
        "   alpha = a / 2\n",
        "   model = Ridge(alpha = alpha) # создание модели с указанным alpha\n",
        "   model.fit(Poly_train, Y_train) # обучение модели по тренировочным полиномеальным данным и по тренировочным Y\n",
        "   # заполняем массив ошибок расчетными значениями\n",
        "   BestRidge = numpy.append(BestRidge, mean_squared_error(Y_test, model.predict(Poly_test)))\n",
        "# вывод массива ошибок\n",
        "print(BestRidge)\n",
        "# вывод информации о лучшем alpha\n",
        "print(\"Лучший alpha в Полиномиальной + Ridge\", numpy.argmin(BestRidge) / 2, \"с среднеквадратичной ошибкой\", BestRidge[numpy.argmin(BestRidge)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestRidge[numpy.argmin(BestRidge)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LsciPjkg97kV",
        "outputId": "270b2107-59b9-4d02-f946-5d54a29f2fb7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ridge + Полиномиальная регрессия\n",
            "[5.10922925 5.13751398 5.12688505 5.11502299 5.10374211 5.09354079\n",
            " 5.0844778  5.07646894 5.0693915  5.06312171 5.05754736 5.05257112\n",
            " 5.04811007 5.04409418 5.04046438 5.0371709  5.0341716  5.03143078\n",
            " 5.02891802 5.0266073  5.0244763 ]\n",
            "Лучший alpha в Полиномиальной + Ridge 10.0 с среднеквадратичной ошибкой 5.024476302293616\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Lasso + Полиномиальная регрессия\n",
        "print(\"Lasso + Полиномиальная регрессия\")\n",
        "BestLasso = numpy.array([]) # создаем пустой массив\n",
        "# Параметр регуляризации берем побольше, чтобы избежать предупреждений о малой регуляризации\n",
        "# Цикл прохода по значениям а от 3000 до 3019 включительно\n",
        "for a in range(3000, 3020):\n",
        "   model = Lasso(alpha = a) # создание модели с указанным параметром alpha\n",
        "   model.fit(Poly_train, Y_train) # обучение модели по тренировочным полиномеаьным данным и тренировочным Y\n",
        "   # заполняем пустой массив ошибок расчетными значениями среднеквадратических ошибок\n",
        "   BestLasso = numpy.append(BestLasso, mean_squared_error(Y_test, model.predict(Poly_test)))\n",
        "# Вывод массива ошибок и информации о лучшем alpha, который соответствует минимальной среднеквадратической ошибке\n",
        "print(BestLasso)\n",
        "print(\"Лучший alpha в Полиномиальной + Lasso\", numpy.argmin(BestLasso) + 3000, \"с среднеквадратичной ошибкой\", BestLasso[numpy.argmin(BestLasso)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestLasso[numpy.argmin(BestLasso)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QoW4lDx4-Qu-",
        "outputId": "14ff1b9c-76da-4fdc-8612-a1af30c681ae"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lasso + Полиномиальная регрессия\n",
            "[8.52172307 8.52212165 8.5225205  8.52291962 8.52331901 8.52371868\n",
            " 8.52411862 8.52451882 8.5249193  8.52532006 8.52572108 8.52612237\n",
            " 8.52652394 8.52692578 8.52732789 8.52773027 8.52813292 8.52853585\n",
            " 8.52893905 8.52934251]\n",
            "Лучший alpha в Полиномиальной + Lasso 3000 с среднеквадратичной ошибкой 8.521723070568992\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  ElasticNet + Полиномиальная регрессия\n",
        "print(\"ElasticNet + Полиномиальная регрессия\")\n",
        "BestElastic = numpy.array([]) # создаем пустой массив среднеквадратических ошибок\n",
        "\"\"\"Коэффициент ratio определяет степень принадлежности метода ElasticNet либо к Lasso, либо к Ridge.\n",
        "Lasso - если aplha большой, Ridge - если alpha маленький\n",
        "Lasso - l1_ratio < 0.5, Ridge - l1_ratio > 0.5\"\"\"\n",
        "# Цикл прохода по параметру ratio от 0 от 9 включительно\n",
        "for ratio in range(10):\n",
        "   \"\"\" значение цикла (ratio) умножается на 333 и к результату прибавляем 10 из-за того что параметр alpha может меняться до примерно 3000\n",
        "   и нужно поделить этот промежуток на 10 частей. А параметр альфа чем больше, тем ближе нам метод к lasso.\n",
        "   Нам нужно знать к чему стремится метод у конкретной модели\"\"\"\n",
        "   alpha = ratio * 333 + 10\n",
        "   \"\"\"параметр ratio может изменяться от 0 до 1 при этом границей между lasso и ridge является 0.5. Промежуток делится на 10 частей.\n",
        "   Вычитаем значение нашего цикла от максимального значения цикла, затем делим на 10 чтобы понять к чему стремится параеметр ratio\n",
        "   (в нашей ситуации при шаге 0.1)\"\"\"\n",
        "   l1 = (10 - ratio) / 10\n",
        "\n",
        "   model = ElasticNet(alpha = alpha, l1_ratio = l1, max_iter = 100000) # создание модели\n",
        "   model.fit(Poly_train, Y_train) # обучение модели по тренировочным полиномеальным данным и по тренировочным Y\n",
        "   # Расчитываются значения среднеквадратической ошибки и заносятся в массив ошибок\n",
        "   BestElastic = numpy.append(BestElastic, mean_squared_error(Y_test, model.predict(Poly_test)))\n",
        "# вывод массива ошибок и информации о лучших alpha и ratio, которые соответствуют минимальной среднеквадратической ошибке\n",
        "print(BestElastic)\n",
        "print(\"Лучшие alpha и l1_ratio в Полиномиальной + ElasticNet\", numpy.argmin(BestElastic) * 333 + 10, (10 - numpy.argmin(BestElastic)) / 10, \"с среднеквадратичной ошибкой\", BestElastic[numpy.argmin(BestElastic)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestElastic[numpy.argmin(BestElastic)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-BV3Labp-dOH",
        "outputId": "618c140d-4854-43b2-8394-6ddfc753e274"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ElasticNet + Полиномиальная регрессия\n",
            "[5.60404868 7.73440554 8.13252055 8.12485869 8.11986623 8.1169497\n",
            " 8.12004665 8.12480369 8.13280495 7.72186724]\n",
            "Лучшие alpha и l1_ratio в Полиномиальной + ElasticNet 10 1.0 с среднеквадратичной ошибкой 5.604048683979123\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Полиномиальная + TheilSenRegressor\n",
        "print(\"Полиномиальная + TheilSenRegressor\")\n",
        "model = TheilSenRegressor(random_state = 100000, max_iter = 1000000, n_subsamples = 500, max_subpopulation = 150)\n",
        "\"\"\" n_subsamples = 500 определяет количество подмножеств со с рандомными значениями\n",
        "(которые генерятся при помощи random_state) для обучения.\n",
        "max_subpopulation = 150 устанавливает максимальный размер подмножеств в выборке.\"\"\"\n",
        "model.fit(Poly_train, Y_train.ravel()) # обучение модели на тренировочных полиномеальных данных и тренировочных Y\n",
        "# ravel() функция которая превращает многомерный массив в одномерный, тк того требует TheilSenRegressor\n",
        "# подсчет и вывод среднеквадратичной ошибки\n",
        "mse = mean_squared_error(Y_test, model.predict(Poly_test))\n",
        "print(\"Cреднеквадратичная ошибка Полиномиальная + TheilSenRegressor\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pml6D6Ga-waw",
        "outputId": "c74abd72-209d-43d4-a475-bb574d132187"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Полиномиальная + TheilSenRegressor\n",
            "Cреднеквадратичная ошибка Полиномиальная + TheilSenRegressor 9.076665066668165\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Полиномиальная + HuberRegressor\n",
        "print(\"Полиномиальная + HuberRegressor\")\n",
        "# Создание и настройка модели HuberRegressor.\n",
        "\"\"\" epsilon - параметр, который определяет границу между использованием квадратичной функции потерь и абсолютной функции потерь.\n",
        "Если абсолютное значение отклонения меньше epsilon, то используется квадратичная функция потерь, в противном случае - абсолютная.\n",
        "Значение по умолчанию обычно составляет 1.35. Параметр epsilon влияет на то, на сколько модель устойчива к выбросам (шумам).\n",
        "Чем больше значение epsilon, тем лучше.\"\"\"\n",
        "model = HuberRegressor(epsilon=100, max_iter=10000, alpha=0.0001)\n",
        "model.fit(Poly_train, Y_train) # обучение модели\n",
        "#  оценка среднеквадратичной ошибки модели на тестовых данных Poly_test.\n",
        "#Эта ошибка измеряет, насколько сильно предсказания модели отклоняются от фактических значений Y_test.\n",
        "mse = mean_squared_error(Y_test, model.predict(Poly_test))\n",
        "print(\"Cреднеквадратичная ошибка Полиномиальная + HuberRegressor\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNe8GRj-_wW7",
        "outputId": "1c3592d0-b85d-4497-a36b-cdf54a1c02ae"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Полиномиальная + HuberRegressor\n",
            "Cреднеквадратичная ошибка Полиномиальная + HuberRegressor 6.171294280275931\n",
            "-----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + LinearRegression\n",
        "print(\"RANSACRegressor + LinearRegression\")\n",
        "\"\"\" min_samples - Определяет минимальное количество точек, которые будут использоваться для подгонки модели в каждой итерации RANSAC.\n",
        "В данном случае, примерно 70% тестовой части данных (800 точек).\n",
        "residual_threshold: Это максимальное отклонение точек от модели, которое считается приемлемым.\n",
        "Точки, отклонение которых превышает это значение, не учитываются при подгонке модели.\"\"\"\n",
        "\n",
        "model = RANSACRegressor(LinearRegression(), min_samples = 800, residual_threshold = 1.0) # создание модели базе линейной регрессии\n",
        "model.fit(X_train, Y_train) # обучение модели на тренировочных значениях\n",
        "# Расчет ошибки и вывод\n",
        "mse = mean_squared_error(Y_test, model.predict(X_test))\n",
        "print(\"Cреднеквадратичная ошибка RANSACRegressor + LinearRegression\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWAz2SHrBlKV",
        "outputId": "1f0ff557-f67b-44a5-cbdc-744b49dd84b0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + LinearRegression\n",
            "Cреднеквадратичная ошибка RANSACRegressor + LinearRegression 4.999895347473191\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + Ridge\n",
        "print(\"RANSACRegressor + Ridge\")\n",
        "BestRidge = numpy.array([]) # создание пустого массива ошибок\n",
        "\"\"\" min_samples - Определяет минимальное количество точек, которые будут использоваться для подгонки модели в каждой итерации RANSAC.\n",
        "В данном случае, примерно 70% тестовой части данных (800 точек).\n",
        "residual_threshold: Это максимальное отклонение точек от модели, которое считается приемлемым.\n",
        "Точки, отклонение которых превышает это значение, не учитываются при подгонке модели.\"\"\"\n",
        "# Цикл прохода по а от 0 до 20 включительно\n",
        "for a in range(21):\n",
        "   alpha = a / 2\n",
        "   model = RANSACRegressor(Ridge(alpha = alpha) , min_samples = 800, residual_threshold = 1.0) # создание модели на базе Ridge с указанием конкретного alpha\n",
        "   model.fit(X_train, Y_train) # обучение модели\n",
        "   BestRidge = numpy.append(BestRidge, mean_squared_error(Y_test, model.predict(X_test))) # расчет ошибки и заполнение массива ошибок нашими значениями\n",
        "\n",
        "print(BestRidge) # вывод массива\n",
        "# Вывод информации о лучшем параметре alpha, который соответствует минимальной среднеквадратической ошибке\n",
        "print(\"Лучший alpha в RANSACRegressor + Ridge\", numpy.argmin(BestRidge) / 2, \"с среднеквадратичной ошибкой\", BestRidge[numpy.argmin(BestRidge)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestRidge[numpy.argmin(BestRidge)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0bFX0SxaCBT4",
        "outputId": "89ebee45-4fd0-4569-af30-ddc450652528"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + Ridge\n",
            "[4.8260326  4.85636819 4.94765812 5.02059067 4.95274126 4.98788135\n",
            " 5.00078232 4.97386389 4.98929203 4.9969265  5.03528743 5.0073467\n",
            " 5.03858318 5.02754497 5.06723254 5.04000104 5.0441169  5.08596761\n",
            " 5.08576992 5.09368427 5.05254034]\n",
            "Лучший alpha в RANSACRegressor + Ridge 0.0 с среднеквадратичной ошибкой 4.8260325982604275\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + Lasso\n",
        "print(\"RANSACRegressor + Lasso\")\n",
        "BestLasso = numpy.array([]) # создание пустого массива ошибок\n",
        "\"\"\" min_samples - Определяет минимальное количество точек, которые будут использоваться для подгонки модели в каждой итерации RANSAC.\n",
        "В данном случае, примерно 70% тестовой части данных (800 точек).\n",
        "residual_threshold: Это максимальное отклонение точек от модели, которое считается приемлемым.\n",
        "Точки, отклонение которых превышает это значение, не учитываются при подгонке модели.\"\"\"\n",
        "# Цикл прохода по а от 1 до 20 включительно\n",
        "for a in range(1, 21):\n",
        "   alpha = a / 2\n",
        "   model = RANSACRegressor(Lasso(alpha = alpha), min_samples = 800, residual_threshold = 1.0) # создание модели на базе lasso с указанием парметра alpha\n",
        "   model.fit(X_train, Y_train) # обучение модели\n",
        "   BestLasso = numpy.append(BestLasso, mean_squared_error(Y_test, model.predict(X_test))) # расчет ошибки и заполнение массива ошибок\n",
        "\n",
        "print(BestLasso) # вывод массива на экран и вывод информации о лучшем alpha, которым соответствует минимальной среднеквадратической ошибки\n",
        "print(\"Лучший alpha в RANSACRegressor + Lasso\", (numpy.argmin(BestLasso) + 1) / 2, \"с среднеквадратичной ошибкой\", BestLasso[numpy.argmin(BestLasso)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestLasso[numpy.argmin(BestLasso)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qKKvic5HGjY",
        "outputId": "5fee8e9f-cb7a-4675-99be-3fe8e3d75ab8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + Lasso\n",
            "[6.06364831 7.18797641 7.23862408 7.30303294 7.36537453 7.4712457\n",
            " 7.63366764 7.57091037 7.59189223 7.84502678 8.10745428 7.96580854\n",
            " 8.65383973 8.78442399 8.91842219 8.99260233 9.07819954 9.77453865\n",
            " 9.38659034 9.79847301]\n",
            "Лучший alpha в RANSACRegressor + Lasso 0.5 с среднеквадратичной ошибкой 6.063648310699348\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + ElasticNet\n",
        "print(\"RANSACRegressor + ElasticNet\")\n",
        "#Lasso - aplha is big, Ridge - alpha is small\n",
        "#Lasso - li_ratio < 0.5, Ridge - l1_ratio > 0.5\n",
        "\"\"\" min_samples - Определяет минимальное количество точек, которые будут использоваться для подгонки модели в каждой итерации RANSAC.\n",
        "В данном случае 1000 точек.\n",
        "residual_threshold: Это максимальное отклонение точек от модели, которое считается приемлемым.\n",
        "Точки, отклонение которых превышает это значение, не учитываются при подгонке модели.\"\"\"\n",
        "BestElastic = numpy.array([]) # создание пустого массива ошибок\n",
        "#  Цикл прохода по параметру ratio от 0 до 9 включительно\n",
        "for ratio in range(10):\n",
        "   alpha = ratio * 2 + 1 # Вычисляется значение alpha на основе текущего значения ratio\n",
        "   l1 = (10 - ratio) / 10 # Вычисляется значение l1_ratio на основе текущего значения ratio\n",
        "\n",
        "   model = RANSACRegressor(ElasticNet(alpha = alpha, l1_ratio = l1), min_samples = 1000, residual_threshold = 0.5) # создание модели на базе ElasticNet\n",
        "   model.fit(X_train, Y_train) # обучение модели\n",
        "   BestElastic = numpy.append(BestElastic, mean_squared_error(Y_test, model.predict(X_test))) # расчет среднеквадратической ошибки и заполнение массива ошибок\n",
        "# вывод массива ошибок и информации о лучшем alpha и ratio, которые соответствуют минимальной среднеквадратической ошибки\n",
        "print(BestElastic)\n",
        "print(\"Лучшие alpha и l1_ratio в RANSACRegressor + ElasticNet\", numpy.argmin(BestElastic) * 2 + 1, (10 - numpy.argmin(BestElastic)) / 10, \"с среднеквадратичной ошибкой\", BestElastic[numpy.argmin(BestElastic)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestElastic[numpy.argmin(BestElastic)])\n",
        "print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5V8k87SvHUf0",
        "outputId": "a4bdc7b0-6e11-4f02-d2fb-3d1e30aebcb6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + ElasticNet\n",
            "[7.12122579 7.4395226  7.76097723 7.98475921 8.07094466 8.18001509\n",
            " 8.06671598 7.98484729 7.80445398 7.60546984]\n",
            "Лучшие alpha и l1_ratio в RANSACRegressor + ElasticNet 1 1.0 с среднеквадратичной ошибкой 7.121225786657732\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + LinearRegression + Полиномиальная регрессия\n",
        "print(\"RANSACRegressor + LinearRegression + Полиномиальная регрессия \")\n",
        "\"\"\" min_samples - Определяет минимальное количество точек, которые будут использоваться для подгонки модели в каждой итерации RANSAC.\n",
        "В данном случае 1000 точек.\n",
        "residual_threshold: Это максимальное отклонение точек от модели, которое считается приемлемым.\n",
        "Точки, отклонение которых превышает это значение, не учитываются при подгонке модели.\"\"\"\n",
        "model = RANSACRegressor(LinearRegression(), min_samples = 1000, residual_threshold = 0.5) # создание модели на базе линейной регрессии\n",
        "model.fit(Poly_train, Y_train) # обучение модели по тренировочным полиномеальным данным и по тренировочным Y\n",
        "# расчет среднеквадратической ошибки и вывод ее на экран, а также вывод на экран информации о лушем значении\n",
        "mse = mean_squared_error(Y_test, model.predict(Poly_test))\n",
        "print(\"Cреднеквадратичная ошибка Полиномиальная + RANSACRegressor + LinearRegression\", mse)\n",
        "MSEOfModels = numpy.append(MSEOfModels, mse)\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyVDz0YlLcz6",
        "outputId": "ca5c6579-b85d-4fd0-c666-96ab95048401"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + LinearRegression + Полиномиальная регрессия \n",
            "Cреднеквадратичная ошибка Полиномиальная + RANSACRegressor + LinearRegression 10.138533048124463\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + Ridge + Полиномиальная регрессия\n",
        "print(\"RANSACRegressor + Ridge + Полиномиальная регрессия \")\n",
        "BestRidge = numpy.array([]) # создаем пустой массив ошибок\n",
        "# Цикл прохода по а от 0 до 20 включительно\n",
        "for a in range(21):\n",
        "   alpha = a / 2 # вычисление значения аlpha на основе значения нашего цикла\n",
        "   model = RANSACRegressor(Ridge(alpha = alpha) , min_samples = 800, residual_threshold = 1.0) # создание модели на основе Ridge с указанием конкретного alpha\n",
        "   model.fit(Poly_train, Y_train) # обучение модели на основе тренировочных полиномеальных данных и тренировочных Y\n",
        "   BestRidge = numpy.append(BestRidge, mean_squared_error(Y_test, model.predict(Poly_test))) # расчет ошибки и заполнение массива ошибок\n",
        "\n",
        "print(BestRidge) # вывод массива на экран\n",
        "# Вывод информации о лучшем alpha, который соответствует наименьшей среднеквадратической ошибке\n",
        "print(\"Лучший alpha в Полиномиальная + RANSACRegressor + Ridge\", numpy.argmin(BestRidge) / 2, \"с среднеквадратичной ошибкой\", BestRidge[numpy.argmin(BestRidge)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestRidge[numpy.argmin(BestRidge)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zAuDIGVhNBwn",
        "outputId": "7077ad37-7ac4-4058-f4ff-78c4e0a4da32"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + Ridge + Полиномиальная регрессия \n",
            "[48.71475873  7.46234997  6.19094859  8.21186181  8.73802387  7.54786697\n",
            "  8.42487083  6.46380028  5.77031247  6.01982516  6.34544622  5.48361831\n",
            "  7.01488433  6.74106465  8.37121957  9.72923874  8.43663142  6.0484898\n",
            "  6.14543823 13.24330609  5.79903911]\n",
            "Лучший alpha в Полиномиальная + RANSACRegressor + Ridge 5.5 с среднеквадратичной ошибкой 5.483618314465247\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + Lasso + Полиномиальная регрессия\n",
        "print(\"RANSACRegressor + Lasso + Полиномиальная регрессия\")\n",
        "BestLasso = numpy.array([])# создаем пустой массив ошибок\n",
        "# Цикл прохода по а от 5000 до 5019 включительно\n",
        "for a in range(5000, 5020):\n",
        "   alpha = a / 2 # вычисление значения аlpha на основе значения нашего цикла\n",
        "   model = RANSACRegressor(Lasso(alpha = alpha), min_samples = 800, residual_threshold = 1.0) # создание модели на основе lasso с указанием конкретного alpha\n",
        "   model.fit(Poly_train, Y_train) # обучение модели на основе тренировочных полиномеальных данных и тренировочных Y\n",
        "   BestLasso = numpy.append(BestLasso, mean_squared_error(Y_test, model.predict(Poly_test))) # расчет ошибки и заполнение массива ошибок\n",
        "\n",
        "print(BestLasso) # вывод массива на экран\n",
        "# Вывод информации о лучшем alpha, который соответствует наименьшей среднеквадратической ошибке\n",
        "print(\"Лучший alpha в Полиномиальная + RANSACRegressor + Lasso\", (numpy.argmin(BestLasso) + 5000) / 2, \"с среднеквадратичной ошибкой\", BestLasso[numpy.argmin(BestLasso)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestLasso[numpy.argmin(BestLasso)])\n",
        "print(\"-----------------------------------------------------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z3vG1gb9OHOJ",
        "outputId": "9c5e29c1-0118-4e87-fdd9-24385b06223c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + Lasso + Полиномиальная регрессия\n",
            "[8.71327603 8.72991666 8.7166779  9.09512097 8.82777661 8.67112396\n",
            " 8.71176203 8.64620413 8.73434019 8.6599164  8.73181421 8.75750433\n",
            " 8.70334459 8.82381281 8.65371693 8.71977727 8.73907934 8.76109519\n",
            " 8.74178087 8.72368302]\n",
            "Лучший alpha в Полиномиальная + RANSACRegressor + Lasso 2503.5 с среднеквадратичной ошибкой 8.64620412625933\n",
            "-----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# RANSACRegressor + ElasticNet + Полиномиальная регрессия\n",
        "print(\"RANSACRegressor + ElasticNet + Полиномиальная регрессия\")\n",
        "#Lasso - aplha is big, Ridge - alpha is small\n",
        "#Lasso - li_ratio < 0.5, Ridge - l1_ratio > 0.5\n",
        "\n",
        "BestElastic = numpy.array([]) # создаем пустой массив ошибок\n",
        "# Цикл прохода по ratio от 0 до 9 включительно\n",
        "for ratio in range(10):\n",
        "   alpha = ratio * 1000 + 2000\n",
        "   l1 = (10 - ratio) / 10\n",
        "\n",
        "   model = RANSACRegressor(ElasticNet(alpha = alpha, l1_ratio = l1), min_samples = 1000, residual_threshold = 0.5) # создание модели ElasticNet с указанием конкретных параметров\n",
        "   model.fit(Poly_train, Y_train) # обучение модели\n",
        "   BestElastic = numpy.append(BestElastic, mean_squared_error(Y_test, model.predict(Poly_test))) # заполняем массив значениями ошибок.\n",
        "   #Далее выводим его и лучший alpha и ratio при минимальной ошибки\n",
        "\n",
        "print(BestElastic)\n",
        "print(\"Лучшие alpha и l1_ratio в Полиномиальная + RANSACRegressor + ElasticNet\", numpy.argmin(BestElastic) * 1000 + 2000, (10 - numpy.argmin(BestElastic)) / 10, \"с среднеквадратичной ошибкой\", BestElastic[numpy.argmin(BestElastic)])\n",
        "MSEOfModels = numpy.append(MSEOfModels, BestElastic[numpy.argmin(BestElastic)])\n",
        "print(\"-----------------------------------------------------------------\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Z-RS29sOyon",
        "outputId": "7ba3b07e-17fc-4363-8245-21b116f06765"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "RANSACRegressor + ElasticNet + Полиномиальная регрессия\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.006e+01, tolerance: 1.020e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.089e+00, tolerance: 9.886e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 7.022e+00, tolerance: 1.124e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 8.734e+00, tolerance: 1.102e+00\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[8.67595642 8.67414858 8.75053092 8.73635735 8.68669442 8.76280624\n",
            " 8.73837037 8.61749138 8.64000306 8.38595006]\n",
            "Лучшие alpha и l1_ratio в Полиномиальная + RANSACRegressor + ElasticNet 11000 0.1 с среднеквадратичной ошибкой 8.385950057246832\n",
            "-----------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.107e+00, tolerance: 9.648e-01\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Итоги\n",
        "print(\"Итоги\")\n",
        "print(\"Лучше всего отработала модель\", AllModels[numpy.argmin(MSEOfModels)], \"с среднеквадратической ошибкой\", MSEOfModels[numpy.argmin(MSEOfModels)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zBxtcpKQaTT",
        "outputId": "90695d2e-e4aa-4d45-f4bd-7b68536be2c7"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Итоги\n",
            "Лучше всего отработала модель KNeighborsRegressor с среднеквадратической ошибкой 4.753353508139491\n"
          ]
        }
      ]
    }
  ]
}